{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.load import *\n",
    "from lib.merged_dataset import *\n",
    "from lib.thumbnail import *\n",
    "from lib.globals import *\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_names, val_img_names, test_img_names, thumbnails_dict = load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the device to be used for training and evaluation\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# print(DEVICE)\n",
    "# # determine if we will be pinning memory during data loading\n",
    "# PIN_MEMORY = True if DEVICE == \"cuda\" else False\n",
    "\n",
    "# create the train and validation datasets\n",
    "trainDS = MergedDataset(wsi_names=train_img_names, mask_thumbnails=thumbnails_dict, pseudo_epoch_length=NUM_PSEUDO_EPOCHS)\n",
    "valDS = MergedDataset(wsi_names=val_img_names, mask_thumbnails=thumbnails_dict, pseudo_epoch_length=NUM_PSEUDO_EPOCHS)\n",
    "print(f\"[INFO] found {len(trainDS)} samples in the merged training set...\")\n",
    "print(f\"[INFO] found {len(valDS)} samples in the merged validation set...\")\n",
    "\n",
    "# create the training and validation data loaders\n",
    "trainLoader = DataLoader(trainDS, shuffle=True,\n",
    "    batch_size=BATCH_SIZE, num_workers=4)\n",
    "valLoader = DataLoader(valDS, shuffle=False,\n",
    "    batch_size=BATCH_SIZE, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulated = torch.empty(0, dtype=torch.int8)\n",
    "for e in tqdm(range(30)):\n",
    "    # loop over the training set\n",
    "    for (x, y) in trainLoader:\n",
    "        accumulated = torch.cat((accumulated,y.flatten()))\n",
    "        # print(y.flatten())\n",
    "        # print(torch.bincount(y.flatten()))\n",
    "    \n",
    "    # Resample the pseudo epoch and refresh data loader\n",
    "    trainDS.resample_pseudo_epoch()\n",
    "    trainLoader = DataLoader(trainDS, shuffle=True,\n",
    "                            batch_size=BATCH_SIZE, num_workers=4)\n",
    "\n",
    "print(accumulated)\n",
    "counts = torch.bincount(accumulated)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = torch.sum(counts)\n",
    "\n",
    "figure, ax = plt.subplots(1,1,figsize=(8,8))\n",
    "x = np.arange(len(counts))\n",
    "\n",
    "labels = [\"Background\", \"Benign\", \"Cancerous\"]\n",
    "\n",
    "ax.bar(x,counts/total)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
